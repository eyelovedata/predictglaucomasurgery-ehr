{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removes slt, lpis, and cat surg codes \n",
    "\n",
    "Remove suspects and hypertensives from negatives \n",
    "\n",
    "require two separate glaucoma diagnoses for negatives\n",
    "\n",
    "require 120 days of follow-up at least for negatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import ast\n",
    "import sklearn \n",
    "import math \n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../../../dbstridefull.db')\n",
    "conn.text_factory = str\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Notes / Unstructured Data for Cohort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsurgnotes=pd.read_sql_query('''select pat_deid, note_deid, substr(note_date, 0, 10) as note_dateonly, effective_dept_id, csn_deid, note from notes \n",
    "where note_desc in (\"Progress Notes\", \"Clinic Visit\") \n",
    "and length(note) > 100 \n",
    "and  pat_deid in (select distinct pat_deid\n",
    "from procedure \n",
    "where  code IN (\n",
    "                '66150',\n",
    "                '66155',\n",
    "                '66160',\n",
    "                '66165',\n",
    "                '66170',\n",
    "                '66172',\n",
    "                '66174',\n",
    "                '66175',\n",
    "                '66179',\n",
    "                '66180',\n",
    "                '66183',\n",
    "                '66184',\n",
    "                '66185',\n",
    "                '67250',\n",
    "                '67255',\n",
    "                '0191T',\n",
    "                '0376T',\n",
    "                '0474T',\n",
    "                '0253T',\n",
    "                '0449T',\n",
    "                '0450T',\n",
    "                '0192T',\n",
    "                '65820',\n",
    "                '65850',\n",
    "                '66700',\n",
    "                '66710',\n",
    "                '66711',\n",
    "                '66720',\n",
    "                '66740',\n",
    "                '66625',\n",
    "                '66540'\n",
    "            )\n",
    "\t\t\t) \n",
    "order by pat_deid''', conn)\n",
    "dfsurgnotes.columns = map(str.lower, dfsurgnotes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsurgnotes.head() #note that this is already sorted by note_date\n",
    "#cell output cleared to protect phi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48682"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfsurgnotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsurgnotes[\"note_dateonly\"]=pd.to_datetime(dfsurgnotes[\"note_dateonly\"])\n",
    "#but we'll sort again just to be absolutely certain: \n",
    "dfsurgnotes.sort_values(by=[\"pat_deid\", \"note_dateonly\"], ascending=True, inplace=True) \n",
    "dfsurgnotes['notecounter'] = dfsurgnotes.groupby([\"pat_deid\"]).cumcount()+1\n",
    "#keep up to first three visit notes only \n",
    "dfsurgnotes=dfsurgnotes[dfsurgnotes[\"notecounter\"]<=3]\n",
    "dfsurgnotes[\"firstnotedate\"]=np.where(dfsurgnotes['notecounter']==1, dfsurgnotes[\"note_dateonly\"], None)\n",
    "dfsurgnotes[\"firstnotedate\"]=dfsurgnotes[\"firstnotedate\"].ffill()\n",
    "dfsurgnotes[\"firstnotedate\"]=pd.to_datetime(dfsurgnotes[\"firstnotedate\"])\n",
    "dfsurgnotes[\"daysfromfirstnote\"] = dfsurgnotes[\"note_dateonly\"]-dfsurgnotes[\"firstnotedate\"]\n",
    "dfsurgnotes=dfsurgnotes[dfsurgnotes[\"daysfromfirstnote\"]<=pd.Timedelta(days=120)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3449"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfsurgnotes.head()\n",
    "len(dfsurgnotes)\n",
    "#dfsurgnotes[\"pat_deid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now exclude the patients who got surgery before 120 days since we need this as a lookback period \n",
    "dfsurgproc=pd.read_sql_query('''select distinct pat_deid, proc_date\n",
    "from procedure \n",
    "where  code IN (\n",
    "                '66150',\n",
    "                '66155',\n",
    "                '66160',\n",
    "                '66165',\n",
    "                '66170',\n",
    "                '66172',\n",
    "                '66174',\n",
    "                '66175',\n",
    "                '66179',\n",
    "                '66180',\n",
    "                '66183',\n",
    "                '66184',\n",
    "                '66185',\n",
    "                '67250',\n",
    "                '67255',\n",
    "                '0191T',\n",
    "                '0376T',\n",
    "                '0474T',\n",
    "                '0253T',\n",
    "                '0449T',\n",
    "                '0450T',\n",
    "                '0192T',\n",
    "                '65820',\n",
    "                '65850',\n",
    "                '66700',\n",
    "                '66710',\n",
    "                '66711',\n",
    "                '66720',\n",
    "                '66740',\n",
    "                '66625',\n",
    "                '66540'\n",
    "            )\n",
    "order by pat_deid''', conn)\n",
    "dfsurgproc.columns = map(str.lower, dfsurgproc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsurgproc[\"proc_date\"]=pd.to_datetime(dfsurgproc[\"proc_date\"])\n",
    "dfsurgproc.sort_values(by=[\"pat_deid\", \"proc_date\"], ascending=True, inplace=True) \n",
    "dfsurgproc['surgcounter'] = dfsurgproc.groupby([\"pat_deid\"]).cumcount()+1\n",
    "#keep first surg only \n",
    "dfsurgproc=dfsurgproc[dfsurgproc[\"surgcounter\"]<=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output cleared to protect phi \n",
    "dfsurgproc.head()\n",
    "dfsurgproc[\"pat_deid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsurg=pd.merge(dfsurgnotes, dfsurgproc, left_on=\"pat_deid\", right_on=\"pat_deid\", how=\"left\")\n",
    "dfsurg[\"daystosurg\"]=dfsurg[\"proc_date\"]-dfsurg[\"firstnotedate\"]\n",
    "#dfsurg[dfsurg[\"daystosurg\"]<pd.Timedelta(days=120)][\"pat_deid\"].value_counts() #how many throwing away?\n",
    "dfsurg=dfsurg[dfsurg[\"daystosurg\"]>=pd.Timedelta(days=120)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1820"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfsurg.head()\n",
    "len(dfsurg)\n",
    "len(dfsurg[\"pat_deid\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#this is an aside, to export the notes before concatenating in order to run Luisa's preprocessing \n",
    "#eventually not used in this project\n",
    "dfsurg[['pat_deid', 'note_deid', 'note']].to_csv('predictglaucomasurgery/surgcohortnotes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate notes# \n",
    "dfsurgconcat=dfsurg.groupby(['pat_deid'])['note'].apply(lambda x: ','.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfsurgconcat.head()\n",
    "#dfsurgconcat[\"note\"][0]\n",
    "len(dfsurgconcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfsurgconcat.to_csv(\"predictglaucomasurgyesnolaser.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have to do the same and compare to a cohort of glaucoma patients who didn't get surgery \n",
    "#select patients with any glaucoma diagnosis - who aren't part of the above list \n",
    "dfnosurgnotes=pd.read_sql_query('''select pat_deid, note_deid, substr(note_date, 0, 10) as note_dateonly, effective_dept_id, csn_deid, note from notes \n",
    "where note_desc = \"Progress Notes\" \n",
    "and length(note) > 100 \n",
    "and pat_deid in (select pat_deid from diagnoses \n",
    "where (replace(icd10_list,'.','') like 'H40%'\n",
    "or replace(icd10_list,'.','') like 'H42%'\n",
    "or replace(icd10_list,'.','') like 'Q150%') \n",
    "and replace(icd10_list,'.','') not like 'H400%'\n",
    "group by pat_deid \n",
    "having count(pat_deid) >=2)\n",
    "and pat_deid not in (select distinct pat_deid\n",
    "from procedure \n",
    "where  code IN (\n",
    "                '66150',\n",
    "                '66155',\n",
    "                '66160',\n",
    "                '66165',\n",
    "                '66170',\n",
    "                '66172',\n",
    "                '66174',\n",
    "                '66175',\n",
    "                '66179',\n",
    "                '66180',\n",
    "                '66183',\n",
    "                '66184',\n",
    "                '66185',\n",
    "                '67250',\n",
    "                '67255',\n",
    "                '0191T',\n",
    "                '0376T',\n",
    "                '0474T',\n",
    "                '0253T',\n",
    "                '0449T',\n",
    "                '0450T',\n",
    "                '0192T',\n",
    "                '65820',\n",
    "                '65850',\n",
    "                '66700',\n",
    "                '66710',\n",
    "                '66711',\n",
    "                '66720',\n",
    "                '66740',\n",
    "                '66625',\n",
    "                '66540'\n",
    "            ))\n",
    "''', conn)\n",
    "dfnosurgnotes.columns = map(str.lower, dfnosurgnotes.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#removing 'H400' removes all suspects, ocular hypertensives, borderline findings, steroid response, and narrow angle diagnoses, e.g. people who don't really have true glaucoma  \n",
    "\n",
    " H40.0 Glaucoma suspect\n",
    " H40.00 Preglaucoma, unspecified\n",
    " H40.001 …… right eye\n",
    " H40.002 …… left eye\n",
    " H40.003 …… bilateral\n",
    " H40.009 …… unspecified eye\n",
    " H40.01 Open angle with borderline findings, low risk\n",
    " H40.011 …… right eye\n",
    " H40.012 …… left eye\n",
    " H40.013 …… bilateral\n",
    " H40.019 …… unspecified eye\n",
    " H40.02 Open angle with borderline findings, high risk\n",
    " H40.021 …… right eye\n",
    " H40.022 …… left eye\n",
    " H40.023 …… bilateral\n",
    " H40.029 …… unspecified eye\n",
    " H40.03 Anatomical narrow angle\n",
    " H40.031 …… right eye\n",
    " H40.032 …… left eye\n",
    " H40.033 …… bilateral\n",
    " H40.039 …… unspecified eye\n",
    " H40.04 Steroid responder\n",
    " H40.041 …… right eye\n",
    " H40.042 …… left eye\n",
    " H40.043 …… bilateral\n",
    " H40.049 …… unspecified eye\n",
    " H40.05 Ocular hypertension\n",
    " H40.051 …… right eye\n",
    " H40.052 …… left eye\n",
    " H40.053 …… bilateral\n",
    " H40.059 …… unspecified eye\n",
    " H40.06 Primary angle closure without glaucoma damage\n",
    " H40.061 …… right eye\n",
    " H40.062 …… left eye\n",
    " H40.063 …… bilateral\n",
    " H40.069 …… unspecified eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnosurgnotes[\"note_dateonly\"]=pd.to_datetime(dfnosurgnotes[\"note_dateonly\"])\n",
    "#but we'll sort again just to be absolutely certain: \n",
    "dfnosurgnotes.sort_values(by=[\"pat_deid\", \"note_dateonly\"], ascending=True, inplace=True) \n",
    "dfnosurgnotes['notecounter'] = dfnosurgnotes.groupby([\"pat_deid\"]).cumcount()+1\n",
    "dfnosurgnotes[\"firstnotedate\"]=np.where(dfnosurgnotes['notecounter']==1, dfnosurgnotes[\"note_dateonly\"], None)\n",
    "dfnosurgnotes[\"firstnotedate\"]=dfnosurgnotes[\"firstnotedate\"].ffill()\n",
    "dfnosurgnotes[\"firstnotedate\"]=pd.to_datetime(dfnosurgnotes[\"firstnotedate\"])\n",
    "dfnosurgnotes[\"daysfromfirstnote\"] = dfnosurgnotes[\"note_dateonly\"]-dfnosurgnotes[\"firstnotedate\"]\n",
    "\n",
    "#figure out who had more than 120 days follow-up \n",
    "dfnosurgfollowup=dfnosurgnotes[dfnosurgnotes[\"daysfromfirstnote\"]>=pd.Timedelta(days=120)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3764"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dfnosurgfollowup[\"pat_deid\"])) #3764 patients with greater than 120 days of follow-up \n",
    "followuplist=list(set(dfnosurgfollowup[\"pat_deid\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep up to first three visit notes only and if they werewithin the first 120 days \n",
    "dfnosurgnotes=dfnosurgnotes[dfnosurgnotes[\"notecounter\"]<=3]\n",
    "dfnosurgnotes=dfnosurgnotes[dfnosurgnotes[\"daysfromfirstnote\"]<=pd.Timedelta(days=120)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and then only keep them if they had >120 days of follow-up \n",
    "dfnosurgnotes=dfnosurgnotes[dfnosurgnotes[\"pat_deid\"].isin(followuplist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfnosurgnotes.head()\n",
    "#cell output cleared for PHI protection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#this is an aside, to export the notes before concatenating in order to run Luisa's preprocessing \n",
    "#not needed for this project \n",
    "dfnosurgnotes[['pat_deid', 'note_deid', 'note']].to_csv('predictglaucomasurgery/nosurgcohortnotes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnosurgconcat=dfnosurgnotes.groupby(['pat_deid'])['note'].apply(lambda x: ','.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnosurgconcat.head()\n",
    "#cell output cleared to protect phi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3764"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfnosurgconcat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfnosurgconcat.to_csv(\"predictglaucomasurgerynofilterednegs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Structured Data for Cohort  - Surgical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpt=pd.read_sql_query('''select pat_deid, birth_date, gender, race, ethnicity from patients \n",
    "where pat_deid in (select distinct pat_deid\n",
    "from procedure \n",
    "where  code IN (\n",
    "                '66150',\n",
    "                '66155',\n",
    "                '66160',\n",
    "                '66165',\n",
    "                '66170',\n",
    "                '66172',\n",
    "                '66174',\n",
    "                '66175',\n",
    "                '66179',\n",
    "                '66180',\n",
    "                '66183',\n",
    "                '66184',\n",
    "                '66185',\n",
    "                '67250',\n",
    "                '67255',\n",
    "                '0191T',\n",
    "                '0376T',\n",
    "                '0474T',\n",
    "                '0253T',\n",
    "                '0449T',\n",
    "                '0450T',\n",
    "                '0192T',\n",
    "                '65820',\n",
    "                '65850',\n",
    "                '66700',\n",
    "                '66710',\n",
    "                '66711',\n",
    "                '66720',\n",
    "                '66740',\n",
    "                '66625',\n",
    "                '66540'\n",
    "            )\n",
    "\t\t\t) \n",
    "order by pat_deid''', conn)\n",
    "dfpt.columns = map(str.lower, dfpt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpt[\"birth_date\"]=pd.to_datetime(dfpt[\"birth_date\"])\n",
    "from datetime import timedelta, date\n",
    "def fix_date(x):\n",
    "    if x.year >=2010:\n",
    "        year = x.year - 100\n",
    "    else:\n",
    "        year = x.year\n",
    "    return date(year,x.month,x.day)\n",
    "\n",
    "dfpt['birth_date'] = dfpt['birth_date'].apply(fix_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3449"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1298"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need diagnoses, medications, and optionally eye exam fields, but only from the first 3 mos \n",
    "dfsurgfirstdate=dfsurgnotes[[\"pat_deid\", \"firstnotedate\"]]\n",
    "len(dfsurgfirstdate)\n",
    "dfsurgfirstdate=dfsurgfirstdate.drop_duplicates() \n",
    "len(dfsurgfirstdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpt=pd.merge(dfpt,dfsurgfirstdate, left_on=\"pat_deid\", right_on=\"pat_deid\", how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpt[\"age\"]=pd.to_datetime(dfpt[\"firstnotedate\"]).dt.year-pd.to_datetime(dfpt[\"birth_date\"]).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfpt[\"firstnotedate\"]\n",
    "del dfpt[\"birth_date\"]\n",
    "dfpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diagnoses \n",
    "dfdx=pd.read_sql_query('''select pat_deid, start_date, icd10_list from diagnoses where pat_deid in (select distinct pat_deid\n",
    "from procedure \n",
    "where  code IN (\n",
    "                '66150',\n",
    "                '66155',\n",
    "                '66160',\n",
    "                '66165',\n",
    "                '66170',\n",
    "                '66172',\n",
    "                '66174',\n",
    "                '66175',\n",
    "                '66179',\n",
    "                '66180',\n",
    "                '66183',\n",
    "                '66184',\n",
    "                '66185',\n",
    "                '67250',\n",
    "                '67255',\n",
    "                '0191T',\n",
    "                '0376T',\n",
    "                '0474T',\n",
    "                '0253T',\n",
    "                '0449T',\n",
    "                '0450T',\n",
    "                '0192T',\n",
    "                '65820',\n",
    "                '65850',\n",
    "                '66700',\n",
    "                '66710',\n",
    "                '66711',\n",
    "                '66720',\n",
    "                '66740',\n",
    "                '66625',\n",
    "                '66540'\n",
    "            )\n",
    "\t\t\t) \n",
    "order by pat_deid''', conn)\n",
    "dfdx.columns = map(str.lower, dfdx.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdx[\"dx_date\"]=pd.to_datetime(dfdx[\"start_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfdx[\"start_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333475"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfdx)\n",
    "#dfdx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdx=pd.merge(dfdx,dfsurgfirstdate, left_on=\"pat_deid\", right_on=\"pat_deid\", how=\"right\")\n",
    "dfdx.sort_values(by=[\"pat_deid\", \"dx_date\"], ascending=True, inplace=True)\n",
    "dfdx=dfdx[(dfdx[\"dx_date\"]-dfdx[\"firstnotedate\"])<=pd.Timedelta(days=120)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdx[\"pivotvalue\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdxwide=dfdx.pivot_table(values=\"pivotvalue\", index='pat_deid', columns='icd10_list', fill_value=0)\n",
    "dfdxwide.columns = ['icd_'+col for col in dfdxwide.columns.values]\n",
    "dfdxwide.reset_index(inplace=True)\n",
    "#dfdxwide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1265"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfdxwide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meds \n",
    "dfmeds=pd.read_sql_query('''select pat_deid, order_time, medication_id from meds where pat_deid in (select distinct pat_deid\n",
    "from procedure \n",
    "where  code IN (\n",
    "                '66150',\n",
    "                '66155',\n",
    "                '66160',\n",
    "                '66165',\n",
    "                '66170',\n",
    "                '66172',\n",
    "                '66174',\n",
    "                '66175',\n",
    "                '66179',\n",
    "                '66180',\n",
    "                '66183',\n",
    "                '66184',\n",
    "                '66185',\n",
    "                '67250',\n",
    "                '67255',\n",
    "                '0191T',\n",
    "                '0376T',\n",
    "                '0474T',\n",
    "                '0253T',\n",
    "                '0449T',\n",
    "                '0450T',\n",
    "                '0192T',\n",
    "                '65820',\n",
    "                '65850',\n",
    "                '66700',\n",
    "                '66710',\n",
    "                '66711',\n",
    "                '66720',\n",
    "                '66740',\n",
    "                '66625',\n",
    "                '66540'\n",
    "            )\n",
    "\t\t\t) \n",
    "order by pat_deid''', conn)\n",
    "dfmeds.columns = map(str.lower, dfmeds.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmeds[\"rx_date\"]=pd.to_datetime(dfmeds[\"order_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfmeds[\"order_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85394"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pat_deid</th>\n",
       "      <th>medication_id</th>\n",
       "      <th>rx_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>22455</td>\n",
       "      <td>2016-11-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1861</td>\n",
       "      <td>10814</td>\n",
       "      <td>2015-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1861</td>\n",
       "      <td>26482</td>\n",
       "      <td>2015-11-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1861</td>\n",
       "      <td>213228</td>\n",
       "      <td>2015-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1861</td>\n",
       "      <td>84953</td>\n",
       "      <td>2016-11-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pat_deid  medication_id    rx_date\n",
       "0      1861          22455 2016-11-21\n",
       "1      1861          10814 2015-07-15\n",
       "2      1861          26482 2015-11-20\n",
       "3      1861         213228 2015-07-15\n",
       "4      1861          84953 2016-11-21"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfmeds)\n",
    "#dfmeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmeds=pd.merge(dfmeds,dfsurgfirstdate, left_on=\"pat_deid\", right_on=\"pat_deid\", how=\"right\")\n",
    "dfmeds.sort_values(by=[\"pat_deid\", \"rx_date\"], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep meds before 120 days after first note \n",
    "dfmeds=dfmeds[(dfmeds[\"rx_date\"]<=(dfmeds[\"firstnotedate\"])+pd.Timedelta(days=120))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24839"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfmeds.head()\n",
    "len(dfmeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmeds[\"pivotvalue\"]=1\n",
    "dfmeds[\"medication_id\"]=dfmeds[\"medication_id\"].astype(int)\n",
    "dfmedswide=dfmeds.pivot_table(values=\"pivotvalue\", index='pat_deid', columns='medication_id', fill_value=0)\n",
    "dfmedswide.columns = ['med_'+str(col) for col in dfmedswide.columns.values]\n",
    "dfmedswide.reset_index(inplace=True)\n",
    "#dfmedswide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1269"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfmedswide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eye exam fields - VA, IOP - stuff we would have on everyone \n",
    "dfexam=pd.read_sql_query('''select pat_deid, DATE_OF_SERVICE, \n",
    "vaoddistcc, vaoddistsc, vaoddistccph, vaoddistscph, vaosdistcc, vaosdistsc, vaosdistccph, vaosdistscph, tod, tos, tmethod\n",
    "from examfield, examparsed \n",
    "where examfield.smartformid = examparsed.smartformid \n",
    "and not (vaoddistcc is null and vaoddistsc is null and vaosdistcc is null and vaosdistsc is null)\n",
    "and pat_deid in (select distinct pat_deid\n",
    "from procedure \n",
    "where  code IN (\n",
    "                '66150',\n",
    "                '66155',\n",
    "                '66160',\n",
    "                '66165',\n",
    "                '66170',\n",
    "                '66172',\n",
    "                '66174',\n",
    "                '66175',\n",
    "                '66179',\n",
    "                '66180',\n",
    "                '66183',\n",
    "                '66184',\n",
    "                '66185',\n",
    "                '67250',\n",
    "                '67255',\n",
    "                '0191T',\n",
    "                '0376T',\n",
    "                '0474T',\n",
    "                '0253T',\n",
    "                '0449T',\n",
    "                '0450T',\n",
    "                '0192T',\n",
    "                '65820',\n",
    "                '65850',\n",
    "                '66700',\n",
    "                '66710',\n",
    "                '66711',\n",
    "                '66720',\n",
    "                '66740',\n",
    "                '66625',\n",
    "                '66540'\n",
    "            )\n",
    "\t\t\t) \n",
    "            order by pat_deid \n",
    "''', conn) \n",
    "dfexam.columns = map(str.lower, dfexam.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51979"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfexam[\"exam_date\"]=pd.to_datetime(dfexam[\"date_of_service\"])\n",
    "del dfexam[\"date_of_service\"]\n",
    "len(dfexam)\n",
    "#dfexam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexam=pd.merge(dfexam,dfsurgfirstdate, left_on=\"pat_deid\", right_on=\"pat_deid\", how=\"right\")\n",
    "dfexam.sort_values(by=[\"pat_deid\", \"exam_date\"], ascending=True, inplace=True)\n",
    "dfexam=dfexam[(dfexam[\"exam_date\"]-dfexam[\"firstnotedate\"])<=pd.Timedelta(days=120)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8699"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfexam)\n",
    "#dfexam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's process the IOPs \n",
    "#we will get the max IOP in each list (for each date), then take the maxiop over all the dates per patient\n",
    "dft=dfexam[[\"pat_deid\", \"exam_date\", \"tod\", \"tos\"]]\n",
    "dft=dft[(dft[\"tod\"]!=\"null\") | (dft[\"tos\"]!=\"null\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmaxt(stringlist): \n",
    "    try: \n",
    "        tlist=ast.literal_eval(stringlist)\n",
    "    except: \n",
    "        return np.nan \n",
    "    numlist=[] \n",
    "    for item in tlist: \n",
    "        try: \n",
    "            itemint=int(item)\n",
    "            numlist.append(itemint)\n",
    "        except: continue  \n",
    "    try: \n",
    "        maxt=max(numlist)\n",
    "    except:\n",
    "        maxt=np.nan\n",
    "    return maxt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft[\"todmax\"]=dft[\"tod\"].apply(getmaxt)\n",
    "dft[\"tosmax\"]=dft[\"tos\"].apply(getmaxt)\n",
    "dft.head()\n",
    "#cell output cleared for PHI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmaxt=pd.concat([dft[[\"pat_deid\", \"todmax\"]].groupby([\"pat_deid\"]).max(),dft[[\"pat_deid\", \"tosmax\"]].groupby([\"pat_deid\"]).max()], axis=1). reset_index()\n",
    "dfmaxt.head()\n",
    "#cell output cleared for PHI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now process the VA's \n",
    "dfva=dfexam[[\"pat_deid\", \"exam_date\", \"vaoddistsc\", \"vaoddistcc\", \"vaoddistscph\", \"vaoddistccph\",\"vaosdistsc\", \"vaosdistcc\", \"vaosdistscph\", \"vaosdistccph\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logmarconversion(va): \n",
    "    #takes a string input in the form of \"20/20\", or \"cf\" \"hm\" etc and spits out a logmar \n",
    "    if len(re.findall('(?i)cf', va))>0: \n",
    "        logmarva=-np.log10(.0025)\n",
    "    elif len(re.findall('(?i)hm', va))>0: \n",
    "        logmarva=-np.log10(.002)\n",
    "    elif len(re.findall('(?i)nlp', va))>0:\n",
    "        logmarva=-np.log10(0.0013)\n",
    "    elif len(re.findall('(?i)lp', va))>0: \n",
    "        logmarva=-np.log10(0.0016)\n",
    "    elif len(re.findall('(?i)20/1600', va))>0: \n",
    "        logmarva=-np.log10(20/1600)\n",
    "    elif len(re.findall('(?i)20/1250', va))>0: \n",
    "        logmarva=-np.log10(20/1250)\n",
    "    elif len(re.findall('(?i)20/1000', va))>0: \n",
    "        logmarva=-np.log10(20/1000)\n",
    "    elif len(re.findall('(?i)20/800', va))>0: \n",
    "        logmarva=-np.log10(20/800)\n",
    "    elif len(re.findall('(?i)20/650', va))>0: \n",
    "        logmarva=-np.log10(20/650)\n",
    "    elif len(re.findall('(?i)20/500', va))>0: \n",
    "        logmarva=-np.log10(20/500)\n",
    "    elif len(re.findall('(?i)20/400', va))>0: \n",
    "        logmarva=-np.log10(20/400)\n",
    "    elif len(re.findall('(?i)20/350', va))>0: \n",
    "        logmarva=-np.log10(20/350)\n",
    "    elif len(re.findall('(?i)20/300', va))>0: \n",
    "        logmarva=-np.log10(20/300)\n",
    "    elif len(re.findall('(?i)20/250', va))>0: \n",
    "        logmarva=-np.log10(20/250)\n",
    "    elif len(re.findall('(?i)20/225', va))>0: \n",
    "        logmarva=-np.log10(20/225)\n",
    "    elif len(re.findall('(?i)20/200', va))>0: \n",
    "        logmarva=-np.log10(20/200)\n",
    "    elif len(re.findall('(?i)20/160', va))>0: \n",
    "        logmarva=-np.log10(20/160)\n",
    "    elif len(re.findall('(?i)20/150', va))>0: \n",
    "        logmarva=-np.log10(20/150)\n",
    "    elif len(re.findall('(?i)20/125', va))>0: \n",
    "        logmarva=-np.log10(20/125)\n",
    "    elif len(re.findall('(?i)20/120', va))>0: \n",
    "        logmarva=-np.log10(20/120)\n",
    "    elif len(re.findall('(?i)20/100', va))>0: \n",
    "        logmarva=-np.log10(20/100)\n",
    "    elif len(re.findall('(?i)20/80', va))>0: \n",
    "        logmarva=-np.log10(20/80)\n",
    "    elif len(re.findall('(?i)20/70', va))>0: \n",
    "        logmarva=-np.log10(20/70)\n",
    "    elif len(re.findall('(?i)20/63', va))>0: \n",
    "        logmarva=-np.log10(20/63)\n",
    "    elif len(re.findall('(?i)20/60', va))>0: \n",
    "        logmarva=-np.log10(20/60)\n",
    "    elif len(re.findall('(?i)20/50', va))>0: \n",
    "        logmarva=-np.log10(20/50)\n",
    "    elif len(re.findall('(?i)20/40', va))>0: \n",
    "        logmarva=-np.log10(20/40)\n",
    "    elif len(re.findall('(?i)20/32', va))>0: \n",
    "        logmarva=-np.log10(20/32)\n",
    "    elif len(re.findall('(?i)20/30', va))>0: \n",
    "        logmarva=-np.log10(20/30)\n",
    "    elif len(re.findall('(?i)20/25', va))>0: \n",
    "        logmarva=-np.log10(20/25)\n",
    "    elif len(re.findall('(?i)20/20', va))>0: \n",
    "        logmarva=-np.log10(20/20)\n",
    "    elif len(re.findall('(?i)20/16', va))>0: \n",
    "        logmarva=-np.log10(20/16)\n",
    "    elif len(re.findall('(?i)20/15', va))>0: \n",
    "        logmarva=-np.log10(20/15)\n",
    "    elif len(re.findall('(?i)20/10', va))>0: \n",
    "        logmarva=-np.log10(20/10)\n",
    "        \n",
    "    else: logmarva=np.nan \n",
    "    return logmarva \n",
    "\n",
    "#now write a function which will take several va inputs and output the bcva logmar \n",
    "def bcvalogmar(vadistsc, vadistcc, vadistscph, vadistccph): \n",
    "    valist=list(filter(None.__ne__, [vadistsc, vadistcc, vadistscph, vadistccph])) #filter's out whichever are None\n",
    "    logmarlist=[] \n",
    "    for va in valist: \n",
    "        if np.isnan(logmarconversion(va)) == False: \n",
    "            logmarlist.append(logmarconversion(va)) \n",
    "    try: bcvalogmar=min(logmarlist)\n",
    "    except ValueError: bcvalogmar=np.nan #if no va's were recorded and all None input then this is an empty list with no minum\n",
    "    return bcvalogmar \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sophia\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Sophia\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dfva[\"bcvalogmarod\"]=dfva[[\"vaoddistsc\", \"vaoddistcc\", \"vaoddistscph\", \"vaoddistccph\"]].apply(lambda x: bcvalogmar(*x), axis=1)\n",
    "dfva[\"bcvalogmaros\"]=dfva[[\"vaosdistsc\", \"vaosdistcc\", \"vaosdistscph\", \"vaosdistccph\"]].apply(lambda x: bcvalogmar(*x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfva=dfva[[\"pat_deid\", \"bcvalogmarod\", \"bcvalogmaros\"]]\n",
    "dfbcva=pd.concat([dfva[[\"pat_deid\", \"bcvalogmarod\"]].groupby([\"pat_deid\"]).min(),dfva[[\"pat_deid\", \"bcvalogmaros\"]].groupby([\"pat_deid\"]).min()], axis=1). reset_index()\n",
    "dfbcva.head()\n",
    "#cell output cleared for PHI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsurgexamfinal=pd.merge(dfbcva, dfmaxt, on=\"pat_deid\", how=\"outer\")\n",
    "dfsurgexamfinal.head()\n",
    "#cell output cleared for PHI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1261"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfsurgexamfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do a giant merge of the data to save it \n",
    "dfsurgexamfinal \n",
    "dfmedswide\n",
    "dfdxwide\n",
    "dfpt\n",
    "#cell output cleared for PHI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsurgstruct=pd.merge(pd.merge(pd.merge(dfpt, dfdxwide, on=\"pat_deid\", how=\"outer\"), \n",
    "         dfmedswide, on='pat_deid', how=\"outer\").fillna(0), \n",
    "        dfsurgexamfinal, on='pat_deid', how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsurgall=pd.merge(dfsurgconcat,dfsurgstruct, on='pat_deid', how='left')\n",
    "#dfsurgall.to_csv(\"predictglaucomasurgeryyesallwolaser.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Structured Data for Cohort  - Non Surgical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpt=pd.read_sql_query('''select pat_deid, birth_date, gender, race, ethnicity from patients\n",
    "where pat_deid in (select pat_deid from diagnoses \n",
    "where (replace(icd10_list,'.','') like 'H40%'\n",
    "or replace(icd10_list,'.','') like 'H42%'\n",
    "or replace(icd10_list,'.','') like 'Q150%') \n",
    "and replace(icd10_list,'.','') not like 'H400%'\n",
    "group by pat_deid \n",
    "having count(pat_deid) >=2)\n",
    "and pat_deid not in (select distinct pat_deid\n",
    "from procedure \n",
    "where  code IN (\n",
    "                '66150',\n",
    "                '66155',\n",
    "                '66160',\n",
    "                '66165',\n",
    "                '66170',\n",
    "                '66172',\n",
    "                '66174',\n",
    "                '66175',\n",
    "                '66179',\n",
    "                '66180',\n",
    "                '66183',\n",
    "                '66184',\n",
    "                '66185',\n",
    "                '67250',\n",
    "                '67255',\n",
    "                '0191T',\n",
    "                '0376T',\n",
    "                '0474T',\n",
    "                '0253T',\n",
    "                '0449T',\n",
    "                '0450T',\n",
    "                '0192T',\n",
    "                '65820',\n",
    "                '65850',\n",
    "                '66700',\n",
    "                '66710',\n",
    "                '66711',\n",
    "                '66720',\n",
    "                '66740',\n",
    "                '66625',\n",
    "                '66540'\n",
    "            )) order by pat_deid \n",
    "''', conn)\n",
    "dfpt.columns = map(str.lower, dfpt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpt[\"birth_date\"]=pd.to_datetime(dfpt[\"birth_date\"])\n",
    "from datetime import timedelta, date\n",
    "def fix_date(x):\n",
    "    if x.year >=2010:\n",
    "        year = x.year - 100\n",
    "    else:\n",
    "        year = x.year\n",
    "    return date(year,x.month,x.day)\n",
    "\n",
    "dfpt['birth_date'] = dfpt['birth_date'].apply(fix_date)\n",
    "\n",
    "dfpt.head()\n",
    "#cell output cleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8744"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3764"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need diagnoses, medications, and optionally eye exam fields, but only from the first 3 mos \n",
    "dfnosurgfirstdate=dfnosurgnotes[[\"pat_deid\", \"firstnotedate\"]]\n",
    "len(dfnosurgfirstdate)\n",
    "dfnosurgfirstdate=dfnosurgfirstdate.drop_duplicates() \n",
    "len(dfnosurgfirstdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpt=pd.merge(dfpt,dfnosurgfirstdate, left_on=\"pat_deid\", right_on=\"pat_deid\", how=\"right\")\n",
    "\n",
    "dfpt[\"age\"]=pd.to_datetime(dfpt[\"firstnotedate\"]).dt.year-pd.to_datetime(dfpt[\"birth_date\"]).dt.year\n",
    "del dfpt[\"firstnotedate\"]\n",
    "del dfpt[\"birth_date\"]\n",
    "dfpt.head()\n",
    "\n",
    "#cell output cleared "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diagnoses \n",
    "dfdx=pd.read_sql_query('''select pat_deid, start_date, icd10_list from diagnoses \n",
    "where pat_deid in (select pat_deid from diagnoses \n",
    "where (replace(icd10_list,'.','') like 'H40%'\n",
    "or replace(icd10_list,'.','') like 'H42%'\n",
    "or replace(icd10_list,'.','') like 'Q150%') \n",
    "and replace(icd10_list,'.','') not like 'H400%'\n",
    "group by pat_deid \n",
    "having count(pat_deid) >=2)\n",
    "and pat_deid not in (select distinct pat_deid\n",
    "from procedure \n",
    "where  code IN (\n",
    "                '66150',\n",
    "                '66155',\n",
    "                '66160',\n",
    "                '66165',\n",
    "                '66170',\n",
    "                '66172',\n",
    "                '66174',\n",
    "                '66175',\n",
    "                '66179',\n",
    "                '66180',\n",
    "                '66183',\n",
    "                '66184',\n",
    "                '66185',\n",
    "                '67250',\n",
    "                '67255',\n",
    "                '0191T',\n",
    "                '0376T',\n",
    "                '0474T',\n",
    "                '0253T',\n",
    "                '0449T',\n",
    "                '0450T',\n",
    "                '0192T',\n",
    "                '65820',\n",
    "                '65850',\n",
    "                '66700',\n",
    "                '66710',\n",
    "                '66711',\n",
    "                '66720',\n",
    "                '66740',\n",
    "                '66625',\n",
    "                '66540'\n",
    "            )) order by pat_deid \n",
    "''', conn)\n",
    "dfdx.columns = map(str.lower, dfdx.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdx[\"dx_date\"]=pd.to_datetime(dfdx[\"start_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfdx[\"start_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580908"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfdx)\n",
    "#dfdx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdx=pd.merge(dfdx,dfnosurgfirstdate, left_on=\"pat_deid\", right_on=\"pat_deid\", how=\"right\")\n",
    "dfdx.sort_values(by=[\"pat_deid\", \"dx_date\"], ascending=True, inplace=True)\n",
    "dfdx=dfdx[(dfdx[\"dx_date\"]-dfdx[\"firstnotedate\"])<=pd.Timedelta(days=120)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfdx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdx[\"pivotvalue\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdxwide=dfdx.pivot_table(values=\"pivotvalue\", index='pat_deid', columns='icd10_list', fill_value=0)\n",
    "dfdxwide.columns = ['icd_'+col for col in dfdxwide.columns.values]\n",
    "dfdxwide.reset_index(inplace=True)\n",
    "dfdxwide.head()\n",
    "#cell output cleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3744"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfdxwide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meds \n",
    "dfmeds=pd.read_sql_query('''select pat_deid, order_time, medication_id from meds \n",
    "where pat_deid in (select pat_deid from diagnoses \n",
    "where (replace(icd10_list,'.','') like 'H40%'\n",
    "or replace(icd10_list,'.','') like 'H42%'\n",
    "or replace(icd10_list,'.','') like 'Q150%') \n",
    "and replace(icd10_list,'.','') not like 'H400%'\n",
    "group by pat_deid \n",
    "having count(pat_deid) >=2)\n",
    "and pat_deid not in (select distinct pat_deid\n",
    "from procedure \n",
    "where  code IN (\n",
    "                '66150',\n",
    "                '66155',\n",
    "                '66160',\n",
    "                '66165',\n",
    "                '66170',\n",
    "                '66172',\n",
    "                '66174',\n",
    "                '66175',\n",
    "                '66179',\n",
    "                '66180',\n",
    "                '66183',\n",
    "                '66184',\n",
    "                '66185',\n",
    "                '67250',\n",
    "                '67255',\n",
    "                '0191T',\n",
    "                '0376T',\n",
    "                '0474T',\n",
    "                '0253T',\n",
    "                '0449T',\n",
    "                '0450T',\n",
    "                '0192T',\n",
    "                '65820',\n",
    "                '65850',\n",
    "                '66700',\n",
    "                '66710',\n",
    "                '66711',\n",
    "                '66720',\n",
    "                '66740',\n",
    "                '66625',\n",
    "                '66540'\n",
    "            )) order by pat_deid \n",
    "''', conn)\n",
    "dfmeds.columns = map(str.lower, dfmeds.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmeds[\"rx_date\"]=pd.to_datetime(dfmeds[\"order_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfmeds[\"order_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70593"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfmeds)\n",
    "#dfmeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmeds=pd.merge(dfmeds,dfnosurgfirstdate, left_on=\"pat_deid\", right_on=\"pat_deid\", how=\"right\")\n",
    "dfmeds.sort_values(by=[\"pat_deid\", \"rx_date\"], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep meds before 120 days after first note \n",
    "dfmeds=dfmeds[(dfmeds[\"rx_date\"]<=(dfmeds[\"firstnotedate\"])+pd.Timedelta(days=120))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70593"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfmeds.head()\n",
    "len(dfmeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmeds[\"pivotvalue\"]=1\n",
    "dfmeds[\"medication_id\"]=dfmeds[\"medication_id\"].astype(int)\n",
    "dfmedswide=dfmeds.pivot_table(values=\"pivotvalue\", index='pat_deid', columns='medication_id', fill_value=0)\n",
    "dfmedswide.columns = ['med_'+str(col) for col in dfmedswide.columns.values]\n",
    "dfmedswide.reset_index(inplace=True)\n",
    "dfmedswide.head()\n",
    "#cell output cleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3633"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfmedswide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eye exam fields - VA, IOP - stuff we would have on everyone \n",
    "dfexam=pd.read_sql_query('''select pat_deid, DATE_OF_SERVICE, \n",
    "vaoddistcc, vaoddistsc, vaoddistccph, vaoddistscph, vaosdistcc, vaosdistsc, vaosdistccph, vaosdistscph, tod, tos, tmethod\n",
    "from examfield, examparsed \n",
    "where examfield.smartformid = examparsed.smartformid \n",
    "and not (vaoddistcc is null and vaoddistsc is null and vaosdistcc is null and vaosdistsc is null)\n",
    "and pat_deid in (select pat_deid from diagnoses \n",
    "where (replace(icd10_list,'.','') like 'H40%'\n",
    "or replace(icd10_list,'.','') like 'H42%'\n",
    "or replace(icd10_list,'.','') like 'Q150%') \n",
    "and replace(icd10_list,'.','') not like 'H400%'\n",
    "group by pat_deid \n",
    "having count(pat_deid) >=2)\n",
    "and pat_deid not in (select distinct pat_deid\n",
    "from procedure \n",
    "where  code IN (\n",
    "                '66150',\n",
    "                '66155',\n",
    "                '66160',\n",
    "                '66165',\n",
    "                '66170',\n",
    "                '66172',\n",
    "                '66174',\n",
    "                '66175',\n",
    "                '66179',\n",
    "                '66180',\n",
    "                '66183',\n",
    "                '66184',\n",
    "                '66185',\n",
    "                '67250',\n",
    "                '67255',\n",
    "                '0191T',\n",
    "                '0376T',\n",
    "                '0474T',\n",
    "                '0253T',\n",
    "                '0449T',\n",
    "                '0450T',\n",
    "                '0192T',\n",
    "                '65820',\n",
    "                '65850',\n",
    "                '66700',\n",
    "                '66710',\n",
    "                '66711',\n",
    "                '66720',\n",
    "                '66740',\n",
    "                '66625',\n",
    "                '66540'\n",
    "            )) order by pat_deid\n",
    "''', conn)\n",
    "dfexam.columns = map(str.lower, dfexam.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexam[\"exam_date\"]=pd.to_datetime(dfexam[\"date_of_service\"])\n",
    "del dfexam[\"date_of_service\"]\n",
    "len(dfexam)\n",
    "dfexam.head()\n",
    "#cell output cleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexam=pd.merge(dfexam,dfnosurgfirstdate, left_on=\"pat_deid\", right_on=\"pat_deid\", how=\"right\")\n",
    "dfexam.sort_values(by=[\"pat_deid\", \"exam_date\"], ascending=True, inplace=True)\n",
    "dfexam=dfexam[(dfexam[\"exam_date\"]-dfexam[\"firstnotedate\"])<=pd.Timedelta(days=120)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14217"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfexam)\n",
    "#dfexam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's process the IOPs \n",
    "#we will get the max IOP in each list (for each date), then take the maxiop over all the dates per patient\n",
    "dft=dfexam[[\"pat_deid\", \"exam_date\", \"tod\", \"tos\"]]\n",
    "dft=dft[(dft[\"tod\"]!=\"null\") | (dft[\"tos\"]!=\"null\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft[\"todmax\"]=dft[\"tod\"].apply(getmaxt)\n",
    "dft[\"tosmax\"]=dft[\"tos\"].apply(getmaxt)\n",
    "#dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmaxt=pd.concat([dft[[\"pat_deid\", \"todmax\"]].groupby([\"pat_deid\"]).max(),dft[[\"pat_deid\", \"tosmax\"]].groupby([\"pat_deid\"]).max()], axis=1). reset_index()\n",
    "dfmaxt.head()\n",
    "#cell output cleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now process the VA's \n",
    "dfva=dfexam[[\"pat_deid\", \"exam_date\", \"vaoddistsc\", \"vaoddistcc\", \"vaoddistscph\", \"vaoddistccph\",\"vaosdistsc\", \"vaosdistcc\", \"vaosdistscph\", \"vaosdistccph\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfva.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sophia\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Sophia\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dfva[\"bcvalogmarod\"]=dfva[[\"vaoddistsc\", \"vaoddistcc\", \"vaoddistscph\", \"vaoddistccph\"]].apply(lambda x: bcvalogmar(*x), axis=1)\n",
    "dfva[\"bcvalogmaros\"]=dfva[[\"vaosdistsc\", \"vaosdistcc\", \"vaosdistscph\", \"vaosdistccph\"]].apply(lambda x: bcvalogmar(*x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfva=dfva[[\"pat_deid\", \"bcvalogmarod\", \"bcvalogmaros\"]]\n",
    "dfbcva=pd.concat([dfva[[\"pat_deid\", \"bcvalogmarod\"]].groupby([\"pat_deid\"]).min(),dfva[[\"pat_deid\", \"bcvalogmaros\"]].groupby([\"pat_deid\"]).min()], axis=1). reset_index()\n",
    "dfbcva.head()\n",
    "#cell output cleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnosurgexamfinal=pd.merge(dfbcva, dfmaxt, on=\"pat_deid\", how=\"outer\")\n",
    "dfnosurgexamfinal.head()\n",
    "#cell output cleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3740"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfnosurgexamfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3764"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnosurgstruct=pd.merge(pd.merge(pd.merge(dfpt, dfdxwide, on=\"pat_deid\", how=\"outer\"), \n",
    "         dfmedswide, on='pat_deid', how=\"outer\").fillna(0), \n",
    "        dfnosurgexamfinal, on='pat_deid', how=\"outer\")\n",
    "len(dfnosurgstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnosurgall=pd.merge(dfnosurgconcat,dfnosurgstruct, on='pat_deid', how='left')\n",
    "#dfnosurgall.to_csv(\"predictglaucomasurgerynoallwolaserfiltered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing, removing nzv features, standardizing, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(748, 4245)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3764, 7677)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsurgall.shape\n",
    "dfnosurgall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsurgall[\"surgery\"]=1\n",
    "dfnosurgall[\"surgery\"]=0\n",
    "#dfsurgall.head()\n",
    "#dfnosurgall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4512, 3325)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcombined=pd.concat([dfsurgall, dfnosurgall], axis=0, join='inner')\n",
    "dfcombined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here can save the nonstandardized version of the dataset with all categorical variables before near zero variance filtration - for use in determining glaucoma severity codes ? Except don't save the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcombined.drop('note', axis=1).to_csv(\n",
    "    \"C:/Users/Sophia/Documents/ResearchPHI/STRIDE_FULL/predictglaucomasurgery/cleanednolaserfilterednegs/predictglaucomasurgerystructnonstandardallcodes.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.887221289729195e-17"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0000000000000053"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize age\n",
    "dfcombined[\"agestandard\"]=(dfcombined[\"age\"]-dfcombined[\"age\"].mean())/dfcombined[\"age\"].std()\n",
    "#check and make sure it worked \n",
    "dfcombined[\"agestandard\"].mean()\n",
    "dfcombined[\"agestandard\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcombined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector=VarianceThreshold(.99 * (1 - .99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4512, 342)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.fit_transform(np.array(dfcombined.loc[:, 'icd_A15.0':'med_541454'])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_threshold_selector(data, threshold=0.5):\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit(data)\n",
    "    return data[data.columns[selector.get_support(indices=True)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfombinednzvfiltered=variance_threshold_selector(dfcombined.loc[:, 'icd_A15.0':'med_541454'], .99 * (1 - .99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bcvalogmarod    2.914191e-15\n",
       "bcvalogmaros    2.510221e-15\n",
       "todmax         -7.005277e-17\n",
       "tosmax          6.509590e-17\n",
       "dtype: float64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "bcvalogmarod    1.0\n",
       "bcvalogmaros    1.0\n",
       "todmax          1.0\n",
       "tosmax          1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize eye exam measures \n",
    "dfexamstandard=(dfcombined.loc[:,'bcvalogmarod':'tosmax']-dfcombined.loc[:,'bcvalogmarod':'tosmax'].mean())/dfcombined.loc[:,'bcvalogmarod':'tosmax'].std()\n",
    "#check and make sure it worked \n",
    "dfexamstandard.mean()\n",
    "dfexamstandard.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bcvalogmarod</th>\n",
       "      <th>bcvalogmaros</th>\n",
       "      <th>todmax</th>\n",
       "      <th>tosmax</th>\n",
       "      <th>todmissing</th>\n",
       "      <th>tosmissing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294232</td>\n",
       "      <td>-0.323032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.531139</td>\n",
       "      <td>-0.548348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.200831</td>\n",
       "      <td>-0.548348</td>\n",
       "      <td>1.106909</td>\n",
       "      <td>0.430014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.400760</td>\n",
       "      <td>-0.163168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bcvalogmarod  bcvalogmaros    todmax    tosmax  todmissing  tosmissing\n",
       "0     -0.294232     -0.323032       NaN       NaN           1           1\n",
       "1     -0.531139     -0.548348       NaN       NaN           1           1\n",
       "2      0.200831     -0.548348  1.106909  0.430014           0           0\n",
       "3     -0.400760     -0.163168       NaN       NaN           1           1\n",
       "4           NaN           NaN       NaN       NaN           1           1"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math \n",
    "def missingindicator(x): \n",
    "    if math.isnan(x): \n",
    "        return 1 \n",
    "    else: \n",
    "        return 0 \n",
    "dfexamstandard[\"todmissing\"]=dfexamstandard[\"todmax\"].apply(missingindicator)\n",
    "dfexamstandard[\"tosmissing\"]=dfexamstandard[\"tosmax\"].apply(missingindicator)\n",
    "dfexamstandard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now fill missing values, equivalent to mean imputation \n",
    "dfexamstandard=dfexamstandard.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time to one-hot encode the demographics \n",
    "dfdemdummies=pd.get_dummies(dfcombined.loc[:,'gender':'ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcombinedprocessed=pd.concat([dfcombined[['pat_deid', 'note','agestandard']], dfdemdummies, dfexamstandard, dfombinednzvfiltered, dfcombined[\"surgery\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcombinedprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcombinedprocessed.to_csv('predictglaucomasurgerycombinedprocessedwolaserfiltered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4512, 364)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcombinedprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3764\n",
       "1     748\n",
       "Name: surgery, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcombinedprocessed[\"surgery\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16578014184397163"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "748/4512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
